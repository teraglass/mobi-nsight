{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e46bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 디렉토리\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_ZIP_PATH = DATA_DIR / \"geolife_raw_clean.zip\"\n",
    "RAW_EXTRACTED_PATH = DATA_DIR / \"raw\"  # 압축 해제 후 경로\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "EXTERNAL_DIR = DATA_DIR / \"external\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXTERNAL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fdfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RAW_EXTRACTED_PATH.exists():\n",
    "    with zipfile.ZipFile(RAW_ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(RAW_EXTRACTED_PATH)\n",
    "    print(\"압축 해제 완료\")\n",
    "else:\n",
    "    print(\"이미 압축 해제됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab3deb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>altitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-07-05 02:53:07</td>\n",
       "      <td>39.999840</td>\n",
       "      <td>116.325001</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-05 02:53:12</td>\n",
       "      <td>39.999899</td>\n",
       "      <td>116.324809</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-07-05 02:53:17</td>\n",
       "      <td>40.000017</td>\n",
       "      <td>116.324672</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-07-05 02:53:22</td>\n",
       "      <td>40.000234</td>\n",
       "      <td>116.324729</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-07-05 02:53:27</td>\n",
       "      <td>40.000363</td>\n",
       "      <td>116.324670</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime        lat         lon  altitude\n",
       "0 2009-07-05 02:53:07  39.999840  116.325001       487\n",
       "1 2009-07-05 02:53:12  39.999899  116.324809       477\n",
       "2 2009-07-05 02:53:17  40.000017  116.324672       468\n",
       "3 2009-07-05 02:53:22  40.000234  116.324729       460\n",
       "4 2009-07-05 02:53:27  40.000363  116.324670       450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_trajectory_file(filepath):\n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        skiprows=6,\n",
    "        names=[\"lat\", \"lon\", \"zero\", \"altitude\", \"date_days\", \"date\", \"time\"],\n",
    "    )\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"date\"] + \" \" + df[\"time\"])\n",
    "    return df[[\"datetime\", \"lat\", \"lon\", \"altitude\"]]\n",
    "\n",
    "# 예시\n",
    "sample_file = list(RAW_EXTRACTED_PATH.glob(\"*.plt\"))[0]\n",
    "df_sample = load_trajectory_file(sample_file)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b534c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17784/17784 [00:00<00:00, 89384.88it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     21\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m❌ Failed to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraj_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m df_all = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m)\u001b[49m.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     24\u001b[39m df_all.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/mobi-nsight/.mobi/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/mobi-nsight/.mobi/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/mobi-nsight/.mobi/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "def add_context_features(df, user_id):\n",
    "    df = df.copy()\n",
    "    df[\"user_id\"] = user_id\n",
    "    df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "    df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
    "    df[\"month\"] = df[\"datetime\"].dt.month\n",
    "    return df\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for user_path in tqdm(sorted(RAW_EXTRACTED_PATH.glob(\"*\"))):\n",
    "    user_id = user_path.name\n",
    "    traj_files = list(user_path.glob(\"*.plt\"))\n",
    "    \n",
    "    for traj_file in traj_files:\n",
    "        try:\n",
    "            df_traj = load_trajectory_file(traj_file)\n",
    "            df_traj = add_context_features(df_traj, user_id)\n",
    "            all_data.append(df_traj)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {traj_file.name}: {e}\")\n",
    "\n",
    "df_all = pd.concat(all_data).reset_index(drop=True)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"hour\", data=df_all)\n",
    "plt.title(\"시간대별 위치 기록 수\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 trajectory 데이터\n",
    "df_all.to_parquet(PROCESSED_DIR / \"trajectories.parquet\", index=False)\n",
    "\n",
    "# 맥락 정보만 별도로 저장\n",
    "df_context = df_all[[\"datetime\", \"user_id\", \"hour\", \"dayofweek\", \"month\"]]\n",
    "df_context.to_parquet(EXTERNAL_DIR / \"context_features.parquet\", index=False)\n",
    "\n",
    "print(\"✅ 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
